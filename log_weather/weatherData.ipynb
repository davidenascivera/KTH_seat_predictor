{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89e5408-0315-4421-b6db-bb2a8382aa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quilan/Projects/Project_scalable/Project_scalable/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from huggingface_hub import login\n",
    "from datasets import Dataset, load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "# Log in to Hugging Face\n",
    "HUGGINGFACE_TOKEN = \"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\"  \n",
    "login(token=HUGGINGFACE_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21a1c707-2a8a-4356-94bc-53cef4fe715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset_from_huggingface(repo_name, file_name):\n",
    "    \"\"\"\n",
    "    Downloads the dataset from a Hugging Face repository.\n",
    "\n",
    "    Parameters:\n",
    "        repo_name (str): Name of the Hugging Face repository.\n",
    "        file_name (str): Name of the dataset file in the repository.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataset as a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    # Push the dataset to Hugging Face Hub\n",
    "    repo_name = \"andreitut/merged_kth_dataset\"  # Replace with your desired repository name\n",
    "   \n",
    "    repo_url = f\"https://huggingface.co/datasets/{repo_name}/resolve/main/{file_name}\"\n",
    "    dataset = pd.read_csv(repo_url, parse_dates=[\"time\"], index_col=\"time\")\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "448b5431-ae36-4f39-b310-1b01636536c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_incremental_weather_data(latitude, longitude, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch incremental weather data from Open-Meteo API for a specific date range.\n",
    "    \"\"\"\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"hourly\": [\"temperature_2m\", \"precipitation\", \"wind_speed_10m\", \"wind_direction_10m\"],\n",
    "        \"timezone\": \"auto\",\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract hourly data\n",
    "    hourly_data = data[\"hourly\"]\n",
    "    weather_df = pd.DataFrame(hourly_data)\n",
    "\n",
    "    # Ensure 'time' exists and is in proper datetime format\n",
    "    if \"time\" in weather_df.columns:\n",
    "        weather_df['time'] = pd.to_datetime(weather_df['time'], errors='coerce')\n",
    "        if weather_df['time'].isnull().any():\n",
    "            raise ValueError(\"Invalid time format detected in API response.\")\n",
    "    else:\n",
    "        raise KeyError(\"'time' column missing in the API response.\")\n",
    "\n",
    "    # Set 'time' as the index\n",
    "    weather_df.set_index('time', inplace=True)\n",
    "\n",
    "    # Debug outputs\n",
    "    print(\"Index type:\", weather_df.index.dtype)  # Confirm datetime\n",
    "    print(\"Columns:\", weather_df.columns)  # Verify other columns\n",
    "    return weather_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c37a9c64-94af-4077-97da-1e76a16a3a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_and_push_dataset(repo_name, latitude, longitude):\n",
    "    \"\"\"\n",
    "    Updates the weather dataset and pushes it to Hugging Face.\n",
    "    \"\"\"\n",
    "    # Step 1: Load the existing dataset\n",
    "    print(\"Loading existing dataset from Hugging Face...\")\n",
    "    existing_data = load_existing_dataset(repo_name)\n",
    "\n",
    "    if not existing_data.empty:\n",
    "        last_date = existing_data.index.max().strftime('%Y-%m-%d')  # Access index\n",
    "    else:\n",
    "        last_date = \"2024-01-01\"  # Default start date if dataset is empty\n",
    "\n",
    "    # Step 2: Fetch new data if needed\n",
    "    start_date = pd.Timestamp(last_date) + pd.Timedelta(days=1)\n",
    "    end_date = pd.Timestamp.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    if start_date <= pd.Timestamp(end_date):\n",
    "        print(f\"Fetching weather data from {start_date} to {end_date}...\")\n",
    "        new_data = get_incremental_weather_data(latitude, longitude, start_date.strftime('%Y-%m-%d'), end_date)\n",
    "\n",
    "        print(\"Fetched data columns:\", new_data.columns)\n",
    "\n",
    "        # Combine existing data with the new data\n",
    "        updated_data = pd.concat([existing_data, new_data])\n",
    "\n",
    "        # Handle duplicates and sort by index (time)\n",
    "        updated_data = updated_data[~updated_data.index.duplicated(keep='last')].sort_index()\n",
    "    else:\n",
    "        print(\"No new data to fetch. Dataset is already up-to-date.\")\n",
    "        return\n",
    "\n",
    "    # Step 3: Push updated dataset to Hugging Face\n",
    "    print(\"Uploading updated dataset to Hugging Face...\")\n",
    "    hf_dataset = Dataset.from_pandas(updated_data)\n",
    "    hf_dataset.push_to_hub(repo_name)\n",
    "    print(f\"Dataset successfully uploaded to Hugging Face Hub: {repo_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a56aa82-6cd2-48a1-a124-d6a910ae04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the dataset from Hugging Face\n",
    "def load_existing_dataset(repo_name):\n",
    "    \"\"\"\n",
    "    Loads the existing dataset from Hugging Face, if available.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset from Hugging Face\n",
    "        hf_dataset = Dataset.load_from_hub(repo_name)\n",
    "        df = hf_dataset.to_pandas()\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "        return df\n",
    "    except:\n",
    "        print(\"No existing dataset found. Starting fresh.\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0878035-303c-4da0-b6bd-ed9a239e37b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing dataset from Hugging Face...\n",
      "No existing dataset found. Starting fresh.\n",
      "Fetching weather data from 2024-01-02 00:00:00 to 2024-12-28...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m latitude, longitude \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m59.3293\u001b[39m, \u001b[38;5;241m18.0686\u001b[39m  \u001b[38;5;66;03m# Stockholm coordinates\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Run the update process\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mupdate_and_push_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatitude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlongitude\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m, in \u001b[0;36mupdate_and_push_dataset\u001b[0;34m(repo_name, latitude, longitude)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_date \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp(end_date):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching weather data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_incremental_weather_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatitude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlongitude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrftime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetched data columns:\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_data\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Combine existing data with the new data\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m, in \u001b[0;36mget_incremental_weather_data\u001b[0;34m(latitude, longitude, start_date, end_date)\u001b[0m\n\u001b[1;32m      5\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://archive-api.open-meteo.com/v1/archive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m: latitude,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m: longitude,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimezone\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m }\n\u001b[0;32m---> 14\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241m.\u001b[39mget(url, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m     15\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     16\u001b[0m data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "repo_name = \"andreitut/weatherDatasetProject\"  # Replace with your repository name\n",
    "latitude, longitude = 59.3293, 18.0686  # Stockholm coordinates\n",
    "\n",
    "\n",
    "# Run the update process\n",
    "update_and_push_dataset(repo_name, latitude, longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c932348-6003-4888-b87c-77543efd5b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b861d518-82a6-47d0-bae5-57c9e57dbd36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e38030-4a12-41e3-87ac-51a99baee894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d56496c-9c05-4022-b67e-968d1e600f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9403b54e-03ab-4881-9e2d-f2cbafb82994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
